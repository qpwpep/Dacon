# @package train.optuna
# A more aggressive preset (Hydra: optuna=tune)
enable: true
metric: f1
n_trials: 120
timeout: null
n_splits: 3
seed: ${train.seed}
sampler: tpe
use_pruner: true
pruner:
  name: median
  n_warmup_steps: 1
study_name: lgbm_tuning_f1
storage: null             # null | "sqlite:///optuna_lgbm.db"
search_space:
  learning_rate: { low: 1.0e-2, high: 1.5e-1, log: true }
  max_depth:
    choices: [-1, 4, 6, 8, 10, 12, 16]
  num_leaves: { low: 16, high: 256, log: true }
  min_child_samples: { low: 5, high: 400, log: true }
  min_split_gain: { low: 1.0e-8, high: 1.0, log: true }
  reg_alpha: { low: 1.0e-8, high: 10.0, log: true }
  reg_lambda: { low: 1.0e-3, high: 500.0, log: true }
  subsample: { low: 0.6, high: 1.0 }
  subsample_freq:
    choices: [0, 1, 2, 5]
  colsample_bytree: { low: 0.4, high: 1.0 }
  max_bin:
    choices: [127, 255, 511]
  scale_pos_weight: { low: 1.0, high: 4.0, log: true }
